---
title: "431 HW7"
author: "Nik Floden"
date: "March 11, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#1
```{r}
y <- c(4,3,1,2,7,6,5, 5,2,3,1,6,4,7, 6,5,1,3,4,2,6,3,4,2,1,5,6,7,4,3,1,2,6,7,5, 3,5,2,1,7,4,6, 6,2,1,3,5,7,4)
contestant <- c(rep(1,7),rep(2,7),rep(3,7),rep(4,7),rep(5,7),rep(6,7),rep(7,7))
judge <- c(rep(c("A","B","C","D","E","F","G"),7))
friedman.test(y, judge, contestant)
```
The Null Hypothesis is that the contestant rankings are the same across all judges. 
The Alternate Hypothesis is that there is at least one judge who's contestant ranking is different from at least one other judge. 
With a p-value of 0.0001015, we reject the null that the contestant rankings are the same across all judges. 

```{r}
lm1 <- lm(y ~ judge*contestant)
anova(lm1)
```

It appears that which judge it is has a heavy effect on the response. 
#2
```{r}
library(gtools)
Prep = 100000

k = 7
b = 7
N = k*b

ybar = mean(y)
ymat <- t(array(y, dim = c(k,b)))

SSt1 <- (mean(ymat[,1])-ybar)^2
SSt2 <- (mean(ymat[,2])-ybar)^2
SSt3 <- (mean(ymat[,3])-ybar)^2
SSt4 <- (mean(ymat[,4])-ybar)^2
SSt5 <- (mean(ymat[,5])-ybar)^2
SSt6 <- (mean(ymat[,6])-ybar)^2
SSt7 <- (mean(ymat[,7])-ybar)^2

SSt0 <- SSt1 + SSt2 + SSt3 + SSt4 + SSt5 + SSt6 + SSt7

Fp = 0
SSX <- 1:Prep
for(i in 1:Prep){
  blk1 = permute(y[seq(1,k)])
  blk2 = permute(y[seq(k+1,2*k)])
  blk3 = permute(y[seq(2*k+1,3*k)])
  blk4 = permute(y[seq(3*k+1,4*k)])
  blk5 = permute(y[seq(4*k+1,5*k)])
  blk6 = permute(y[seq(5*k+1,6*k)])
  blk7 = permute(y[seq(6*k+1,7*k)])
  
  yp = rbind(blk1, blk2, blk3, blk4, blk5, blk6, blk7)
  
  SSt1 <- (mean(yp[,1])-ybar)^2
  SSt2 <- (mean(yp[,2])-ybar)^2
  SSt3 <- (mean(yp[,3])-ybar)^2
  SSt4 <- (mean(yp[,4])-ybar)^2
  SSt5 <- (mean(yp[,5])-ybar)^2
  SSt6 <- (mean(yp[,6])-ybar)^2
  SSt7 <- (mean(yp[,7])-ybar)^2
  
  SSX[i] <- SSt1 + SSt2 + SSt3 + SSt4 + SSt5 + SSt6 + SSt7
  
  if(SSX[i] >= SSt0) Fp = Fp+1
}
Fp / Prep
plot(ecdf(SSX))
```

The p-value is 0, which leads me to believe that the p-value is less than .00001, from which I conclude to reject the null hypothesis. 

#3

```{r}
library(statmod)
library(doBy)
library(ade4)
library(RVAideMemoire)

y <- c(0,0,1,0,0, 0,0,0,1,0, 0,1,1,1,1, 0,0,1,0,1, 0,1,0,0,0,
       0,0,0,0,0, 1,0,1,0,0, 0,0,1,1,1, 0,0,1,0,0, 1,1,1,1,1,
       0,0,1,0,0, 0,0,1,1,1, 1,0,1,0,0, 0,1,0,1,1, 0,0,0,1,1,0,0,1,0,0)

block <- c(1,1,1,1,1,2,2,2,2,2,3,3,3,3,3,4,4,4,4,4,5,5,5,5,5,
           6,6,6,6,6,7,7,7,7,7,8,8,8,8,8,9,9,9,9,9,10,10,10,10,10,
           11,11,11,11,11,12,12,12,12,12,13,13,13,13,13,14,14,14,14,14,
           15,15,15,15,15,16,16,16,16,16)

fertilizer <- c(rep(c("A","B","C","D","E"),16))

cochran.qtest(y~fertilizer|block, alpha = 0.5, p.method = "fdr")
```

The Null is that the fertilizers are equally effective, the alternative is that the fertilizers do not all have the same effect. 
With a p=value of 0.02441, we reject the null hypothesis. 

#4
```{r}
Visual  <- c(75,69,70,65,68,62,55,50,52,40,45,41,42,39,37,34)
Reading <- c(95,90,82,75,70,69,65,60,58,55,44,94,23,83,53,20)

```

a)
```{r}
cor.test(Visual,Reading,method="spearman",alternative = c("two.sided"))
```

```{r}
cor.test(Visual,Reading,method="kendall",alternative = c("two.sided"))
```

b)I would reject that null for both at the 0.05 level. 

c) I wouldn't recommend them, it's likely that the data follows some form of distribution, thus Pearson's r is likely more appropriate. 

#5
a)
```{r}
JudgeA <- c(1,2,4,3,5,6,8,7)
JudgeB <- c(2,1,3,4,5,7,8,6)
cor.test(JudgeA,JudgeB, method = "spearman", alternative = c("two.sided"))
```

b)
```{r}
JudgeC <- c(7,6,4,5,3,1,8,2)
JudgeD <- c(6,7,5,4,3,2,8,1)
cor.test(JudgeC,JudgeD, method = "spearman", alternative = c("two.sided"))
```

c)
```{r}
response <- c(1,2,4,3,5,6,8,7,
              2,1,3,4,5,7,8,6,
              7,6,4,5,3,1,8,2,
              6,7,5,4,3,2,8,1)
spec <- c(rep(c("1","2","3","4","5","6","7","8"),4))
judge <- c(rep("A",8), rep("B",8), rep("C",8), rep("D",8))
friedman.test(response,spec,judge)
```

d)
We can say that A & B are not correlated, and C&D are not correlated, however we can say that A,B,C,& D have some form of association between all of them. 